Containers Vocab:

Container host:
	1)Container Engine
	2)Container runtime
	3)Linux Kernel

Container Engine-A container engine can loosely be described as any tool which provides an API or CLI for building or running containers. This started with Docker, but also includes Podman, Buildah, rkt, and CRI-O. A container engine accepts user inputs, pulls container images, creates some metadata describing how to run the container, then passes this information to a container Runtime.
   -Docker(Requires daemon)
   -Podman(Daemonless)

Container runtime-A container runtime is a small tool that expects to be handed two things - a directory often called a root filesystem (or rootfs), and some metadata called config.json (or spec file). The most common runtime runc is the default for every container engine mentioned above. However, there are many innovative runtimes including katacontainers, gvisor, crun, and railcar.
	-containerd(ctr: high level)
	-runc(low level)

Linux Kernel-The kernel is responsible for the last mile of container creation, as well as resource management during its running lifecycle. The container runtime talks to the kernel to create the new container with a special kernel function called clone(). The runtime also handles talking to the kernel to configure things like cgroups, SELinux, and SECCOMP (more on these later). The combination of kernel technologies invoked are defined by the container runtime, but there are very recent efforts to standardize this in the kernel.

Containers-Containers are just regular Linux processes that were started as child processes of a container runtime instead of by a user running commands in a shell. All Linux processes live side by side, whether they are daemons, batch jobs or user commands - the container engine, container runtime, and containers (child processes of the container runtime) are no different. All of these processes make requests to the Linux kernel for protected resources like memory, RAM, TCP sockets, etc.

Image/Repository(.tar files with a .json file):Image layers in a repository are connected together in a parent-child relationship. Each image layer represents changes between itself and the parent layer.
   -Tools to see each layer-dive(https://github.com/wagoodman/dive)
   -Images are stored in registry server(FQDN-hub.docker.com) e.g docker pull REGISTRY_SERVER/NAMESPACE/REPOSITORY[:TAG]
   -A namespace is a tool for separating groups of repositories. On the public DockerHub, the namespace is typically the username of the person sharing the image, but can also be a group name, or a logical name.

Tags:There is one special tag - latest - which typically points to the layer containing the latest version of software in the repository

Container Runtime(runc by default)-
   Consuming the container mount point provided by the Container Engine (can also be a plain directory for testing)
   Consuming the container metadata provided by the Container Engine (can be a also be a manually crafted config.json for testing)
   Communicating with the kernel to start containerized processes (clone system call)
   Setting up cgroups
   Setting up SELinux Policy
   Setting up App Armor rules


cgroups(Control groups)- resource management for process

namespaces- While cgroups control how much resources a process can use, Namespaces control what a process and see and access.
lsns -p <PID of container process>

Overlay file system:

pivot_root: Used for mounting image filesystem to / root inside container process.

Container= Namespaces + Cgroups + Layers + Overlay Filesystem + Pivot_root

----------------------------------------------------------------------------------------------------



docker images //see all the available images

docker rmi //remove images

docker run --name ubu -it ubuntu:18.04  //run image

docker ps //to see currently running processes

docker ps -a //to see processes which were running earlier

docker stop container_id

docker rm container_id

docker exec â€“it nginx-test /bin/bash  //nginx-test is name of container.FYI this is for getting shell of a running container

docker save fudforum_3.0.9 > fudforum_3.0.9.tar //save images

docker load --input fudforum_3.0.9.tar //

docker system prune

docker container run --publish 80:80 --detach nginx

docker container ls

docker container stop 6c1

docker container logs infallible_mendel

docker container top silly_haslett (shows the running processes of the container)

docker rm $(docker ps -a -q)

ps aux | grep mongd

docker container inspect exciting_borg

docker container stats exciting_borg

docker container run -it nginx bash(runs bash instead of default start command of image)

docker container run --rm -it nginx bash(-rm will remove the continer when it stops)

docker container exec 

docker container start -ai ubuntu

docker container exec -it youthful_brown bash (exec is used to run additional command without affecting existing running command)

docker attach <container_id>

docker export -o 

docker export -o alpine.tar 182329d8e111

----------------------------------------------------------Networking related commands-----------------------------------------------
2. Networking related commands
	a)docker container inspect --format '{{.NetworkSettings.IPAddress}}' 2cb (gives the ip address assigned to the container)
	b)docker network ls (shows the available networks)
	c)docker network inspect bridge (inspecting a docker network)
	d)docker network create my_net (creating own docker neteork)
	e)docker network connect bridge zen_goldstine (connecting container to a network)
	f)docker container run -d --net dude --net-alias search elatic search:2 (--net-alias is used to give alias dns-Can be used for dns round robin) 

-----------------------------------------------------------Docker File related commands-----------------------------------------------------
3. Docker file
	a)FROM debian:jessie
	b)RUN (run bash commands)
	c)EXPOSE 80 443 (expose these ports on docker virtul network, -p will still be required to get these on host)
	d)CMD []
	e)docker build -f some-docker_file
	f)WORKDIR /usr/share (running cd path)
	g)COPY index.html index.html (copying file from local host use . . to copy everything)
	h)It is better to keep the things which changes more at bottom in docker file as the upper coomands will use use previous cache and need not to run again.
	i)docker image tag nginx-wth-html:latest bretfisher/nginx-wth-html:latest (for changing tag to push the image to dockerhub)
	j)docker build -t assignment1 .
	k)docker run --rm -p 30000:80 assignment1

------------------------------------------------------------Docker system cleaning commands-----------------------------------------------------
4.docker system cleaning commands
	a)docker image prune
	b)docker system prune
	c)docker image prune -a ( which will remove all images you're not using)
	d)docker system df (to see space usage)
	e)docker container logs -f plsql
	f)docker kill $(docker ps -q) # stopping all containers
   g) docker rm $(docker ps -a -q) # Removing all contianers

----------------------------------------------------------Docker bind volume--------------------------------------------------------------------

5.docker bind volume
	a)docker container run -d --name nginx -p 80:80 -v /host_dir:/web_server_root_dir nginx

	docker cp <file to copy>  <container_id>:<path inside container>
 
-------------------------------------------------docker compose(multi container setup)-----------------------------------------------------------------------
6. 
	a)docker-compose up
	b)docker-compose down

------------------------------------------------docker REST API(This is what docker cli uses)-----------------------------------------------------
7. 
	a)curl --unix-socket /var/run/docker.sock http://localhost/images/json | jq
	b)curl http://localhost:2375/images/json | jq

----------------------------------------------------------swarm------------------------------------------------
a)docker info(to check swarm status)
b)docker swarm init (to enable swarm in system)
c)docker node ls
d)docker service create alping ping 8.8.8.8 (creating swarm service)
e)docker service ls
f)docker service ps z25(give container ls like output-with additional column of node)
g)docker service update <ID> --replicas 3(scaling up(now if we accidendently delete any one container then swarm will automatically run it ))


----------------------------------------------------------swarm cluster------------------------------------------
a)Spun up 3 identical vms all with docker installed.
b)docker swarm init
c)docker swarm join-token manager
d)docker node ls
e)docker node update --role manager <worker id>(workers cannot use swarm commands to allow them) 
f)docker service create --replicas 3 alpine ping 8.8.8.8
g)overlay network(network used for swarm)
	1)docker network create --driver overlay mydrupal

---------------------------------------------------------docker stack--------------------------------------------
a)docker stack deploy -c <stack-file>(Similar to that docker-compose file, also works even if docker-compose cli is not there)
	1)running multiple services from a single stack file, 
	2)also each service can run on multiple nodes.
	3)Note that each stack can run only one swarm i.e only one cluster.

b) echo password | docker secret create psql-pw(adding secrets) -

----------------------------------docker secrets for local development(without swarm) -------------------------------------------------
1)docker-compose up -d(spun up  a container via docker file in secrets-sample2 folder)
2)docker-compose exec psql cat /run/secrets/psql_user
3)docker-compose -f docker-compose.yml -f docker-compose.prod.yml config > output.yml (combining local file and production file into one file)

--------------------------------------------------docker service update-------------------------------------------------------------------
1)docker service create -p 8088:80 --name web nginx:1.13.7
2)docker service scale web=5
3)docker service update --publish-rm 8088 --publish-add 9090:80 web


---------------------------------------------------------docker healthchecks---------------------------------------------------------------
1)docker container ls
2)docker container inspect
3)docker container run --name p2 -d --health-cmd="pg_isready -U postgres || exit 1" postgres

--------------------------------------------------------------docker local registry------------------------------------------------------
1)docker container run  -d -p 5000:5000 --name registry registry
2)docker  tag hello-world 127.0.0.1:5000/hello-world
3)docker pull 127.0.0.1:5000/hello-world
4)docker container run -d -p 5000:5000 --name registry -v $(pwd)/registry-data:/var/lib/registry registry (deploy using volume)


------------------------------------------------------Automated scanners-------------------------
trivy image python:3.4-alpine



